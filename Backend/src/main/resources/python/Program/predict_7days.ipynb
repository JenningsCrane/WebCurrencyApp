{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5fadef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominal</th>\n",
       "      <th>data</th>\n",
       "      <th>curs</th>\n",
       "      <th>cdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.12.2023</td>\n",
       "      <td>12.6503</td>\n",
       "      <td>Китайский юань</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.12.2023</td>\n",
       "      <td>12.5636</td>\n",
       "      <td>Китайский юань</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.12.2023</td>\n",
       "      <td>12.4993</td>\n",
       "      <td>Китайский юань</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15.12.2023</td>\n",
       "      <td>12.5457</td>\n",
       "      <td>Китайский юань</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16.12.2023</td>\n",
       "      <td>12.6091</td>\n",
       "      <td>Китайский юань</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nominal        data     curs             cdx\n",
       "0        1  12.12.2023  12.6503  Китайский юань\n",
       "1        1  13.12.2023  12.5636  Китайский юань\n",
       "2        1  14.12.2023  12.4993  Китайский юань\n",
       "3        1  15.12.2023  12.5457  Китайский юань\n",
       "4        1  16.12.2023  12.6091  Китайский юань"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "# граница валидационных данных\n",
    "VAL_SPLIT = 0\n",
    "\n",
    "# Получаем входные значения\n",
    "arguments = sys.argv\n",
    "\n",
    "#if arguments[1] == \"cny\":\n",
    "    # Путь к директории с моделью\n",
    "    directory = \"..\\\\model\\cny_model.keras\"\n",
    "    dir_new_dataset = '..\\\\new_dataset\\\\cny.csv'\n",
    "    # Путь к директории для сохранения файла json\n",
    "    json_dir = \"..\\\\json\"\n",
    "    # Имя файла json\n",
    "    filename = \"cny_data.json\"\n",
    "#elif arguments[1] == \"aed\":\n",
    "    # Путь к директории с моделью\n",
    "    directory = \"..\\\\model\\aed_model.keras\"\n",
    "    dir_new_dataset = '..\\\\new_dataset\\\\aed.csv'\n",
    "    # Путь к директории для сохранения файла json\n",
    "    json_dir = \"..\\\\json\"\n",
    "    # Имя файла json\n",
    "    filename = \"aed_data.json\"\n",
    "#else:\n",
    "#    print(\"Нет входных аргументов\")\n",
    "#    quit()\n",
    "\n",
    "# настройки для обучения\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "def check_csv_file_size(file_path):\n",
    "    global VAL_SPLIT\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        num_records = len(df)\n",
    "        if (num_records >= 60):\n",
    "            VAL_SPLIT = int(num_records * 0.1)\n",
    "            return num_records\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "# Загрузка данных из CSV файла\n",
    "df = pd.read_csv(dir_new_dataset, on_bad_lines='skip', sep=';')\n",
    "\n",
    "# Проверка размера файла CSV\n",
    "if (not check_csv_file_size(dir_new_dataset)):\n",
    "    print(\"Размер файла CSV меньше 60 записей. Дополните выборку.\")\n",
    "    quit()\n",
    "\n",
    "print(VAL_SPLIT)\n",
    "print(EVALUATION_INTERVAL)\n",
    "# Преобразование значений столбца 'curs' из строки в число с корректным разделителем\n",
    "df['curs'] = df['curs'].str.replace(',', '.').astype(float)\n",
    "# Применение логики для разделения значений столбцов 'nominal' и 'curs'\n",
    "df['curs'] = df.apply(lambda row: row['curs'] / 10.0 if row['nominal'] == 10 else row['curs'], axis=1)\n",
    "\n",
    "df['nominal'] = df['nominal'].apply(lambda x: x / 10 if x == 10 else x)\n",
    "\n",
    "# Переворачивание порядка столбцов, кроме первого\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:][::-1].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90f4f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция подготовки данных для входа в рекурентную сеть\n",
    "def univariate_data(dataset, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "\n",
    "    labels.append(dataset[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b784a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем курс и индексируем по дате\n",
    "uni_data = df['curs']\n",
    "uni_data.index = df['data']\n",
    "uni_data.head()\n",
    "uni_data = uni_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0d55e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# номализация данных\n",
    "uni_train_mean = uni_data[:VAL_SPLIT].mean()\n",
    "uni_train_std = uni_data[:VAL_SPLIT].std()\n",
    "uni_data = (uni_data-uni_train_mean)/uni_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "871d7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 30\n",
    "future_target = 7\n",
    "STEP = 1\n",
    "\n",
    "x_val_uni, y_val_uni = univariate_data(uni_data, VAL_SPLIT, None, past_history, future_target, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b423b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка данных для модели\n",
    "val_data_uni = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_data_uni = val_data_uni.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1a7f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "[12.605846 12.619503 12.621521 12.621353 12.602325 12.624196 12.621348]\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_keras_format(directory):\n",
    "    model = tf.keras.models.load_model(directory, custom_objects={'mae': tf.keras.losses.mean_absolute_error})\n",
    "    return model\n",
    "\n",
    "model = load_model_from_keras_format(directory)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n",
    "for x, y in val_data_uni.take(1):\n",
    "  print((model.predict(x)[0]* uni_train_std) + uni_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81d4aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "JSON-файл сохранен по пути: ..\\json/data.json\n"
     ]
    }
   ],
   "source": [
    "predictions = []  # Создание пустого списка для предсказаний\n",
    "\n",
    "# Получение предсказаний и добавление их в список\n",
    "for x, y in val_data_uni.take(1):\n",
    "    prediction = (model.predict(x)[0] * uni_train_std) + uni_train_mean\n",
    "    predictions.append(prediction.tolist())  # Преобразование массива numpy в список и добавление в список предсказаний\n",
    "\n",
    "json_data = json.dumps(predictions)  # Сериализация списка в JSON\n",
    "\n",
    "# Сохранение JSON-данных в файл\n",
    "with open(json_dir + \"/\" + filename, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"JSON-файл сохранен по пути:\", json_dir + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6001d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
